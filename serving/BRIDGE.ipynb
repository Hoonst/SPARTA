{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d7071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append('../TabularSemanticParsing')\n",
    "# sys.path.extend(['../SQLova','../TabularSemanticParsing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ada3dc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.eval.wikisql.lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2a712884a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bridge Model Define\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemantic_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_framework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderLFramework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemantic_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_configs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_dirs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mensemble_model_dirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikisql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SPARTA/TabularSemanticParsing/src/semantic_parser/learn_framework.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoz_sp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_framework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLFramework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_modules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaskedCrossEntropyLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SPARTA/TabularSemanticParsing/src/common/learn_framework.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_wandb_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wandb_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_no_join_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_tools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0meval_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0meval_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikisql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SPARTA/TabularSemanticParsing/src/eval/eval_tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspider_eval_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikisql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikisql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwikisql_eval_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSPIDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.eval.wikisql.lib'"
     ]
    }
   ],
   "source": [
    "# Bridge Model Define\n",
    "from src.semantic_parser.learn_framework import EncoderDecoderLFramework\n",
    "from src.semantic_parser.ensemble_configs import model_dirs as ensemble_model_dirs\n",
    "from src.eval.wikisql.lib.dbengine import DBEngine\n",
    "\n",
    "from src.demos.demos import Text2SQLWrapper\n",
    "from src.data_processor.path_utils import get_model_dir, get_checkpoint_path\n",
    "from src.data_processor.schema_graph import SchemaGraph\n",
    "from src.data_processor.vocab_processor import build_vocab\n",
    "from src.data_processor.data_processor import preprocess\n",
    "from src.data_processor.processors.data_processor_wikisql import generate_sql_q, generate_sql_q1\n",
    " \n",
    "import src.utils.utils as utils\n",
    "import src.eval.eval_tools as eval_tools\n",
    "\n",
    "import src.data_processor.processor_utils as data_utils\n",
    "import src.data_processor.data_loader as data_loader\n",
    "import src.common.ops as ops\n",
    "import random\n",
    "\n",
    "import ast\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# args_bridge = parser.parse_args(args=[])\n",
    "from src.parse_args import args as args_bridge\n",
    "\n",
    "args_bridge.data_dir=\"../TabularSemanticParsing/data/ko_from_table\"\n",
    "args_bridge.db_dir=\"../TabularSemanticParsing/data/ko_from_table\"\n",
    "args_bridge.dataset_name=\"wikisql\"\n",
    "args_bridge.model=\"bridge\"\n",
    "args_bridge.model_id = 2\n",
    "args_bridge.question_split=True\n",
    "args_bridge.query_split=False\n",
    "args_bridge.question_only=True\n",
    "args_bridge.normalize_variables=False\n",
    "args_bridge.denormalize_sql=True\n",
    "args_bridge.omit_from_clause=True\n",
    "args_bridge.table_shuffling=True\n",
    "args_bridge.use_graph_encoding=False\n",
    "args_bridge.use_typed_field_markers=False\n",
    "args_bridge.use_lstm_encoder=True\n",
    "args_bridge.use_meta_data_encoding=True\n",
    "args_bridge.use_picklist=True\n",
    "args_bridge.no_anchor_text=False\n",
    "args_bridge.anchor_text_match_threshold=0.85\n",
    "args_bridge.top_k_picklist_matches=2\n",
    "args_bridge.atomic_value_copy=False\n",
    "args_bridge.process_sql_in_execution_order=False\n",
    "args_bridge.sql_consistency_check=False\n",
    "args_bridge.share_vocab=False\n",
    "args_bridge.sample_ground_truth=False\n",
    "args_bridge.save_nn_weights_for_visualizations=True\n",
    "args_bridge.vocab_min_freq=0\n",
    "args_bridge.text_vocab_min_freq=0\n",
    "args_bridge.program_vocab_min_freq=0\n",
    "args_bridge.max_in_seq_len=512\n",
    "args_bridge.max_out_seq_len=60\n",
    "\n",
    "args_bridge.num_steps=10000\n",
    "args_bridge.curriculum_interval=0\n",
    "args_bridge.num_peek_steps=400\n",
    "args_bridge.num_accumulation_steps=3\n",
    "args_bridge.save_best_model_only=True\n",
    "args_bridge.train_batch_size=8\n",
    "args_bridge.dev_batch_size=8\n",
    "args_bridge.encoder_input_dim=768\n",
    "args_bridge.encoder_hidden_dim=512\n",
    "args_bridge.decoder_input_dim=512\n",
    "args_bridge.num_rnn_layers=1\n",
    "args_bridge.num_const_attn_layers=0\n",
    "args_bridge.use_oracle_tables=False\n",
    "args_bridge.num_random_tables_added=0\n",
    "args_bridge.use_additive_features=False\n",
    "args_bridge.schema_augmentation_factor=1\n",
    "args_bridge.random_field_order=False\n",
    "args_bridge.data_augmentation_factor=1\n",
    "args_bridge.augment_with_wikisql=False\n",
    "args_bridge.num_values_per_field=0\n",
    "args_bridge.pretrained_transformer=\"bert-base-multilingual-cased\"\n",
    "args_bridge.fix_pretrained_transformer_parameters=False\n",
    "args_bridge.bert_finetune_rate=0.00005\n",
    "args_bridge.learning_rate=0.0003\n",
    "args_bridge.learning_rate_scheduler=\"inverse-square\"\n",
    "args_bridge.trans_learning_rate_scheduler=\"inverse-square\"\n",
    "args_bridge.warmup_init_lr=0.0003\n",
    "args_bridge.warmup_init_ft_lr=0\n",
    "args_bridge.num_warmup_steps=3000\n",
    "args_bridge.emb_dropout_rate=0.3\n",
    "args_bridge.pretrained_lm_dropout_rate=0\n",
    "args_bridge.rnn_layer_dropout_rate=0.1\n",
    "args_bridge.rnn_weight_dropout_rate=0\n",
    "args_bridge.cross_attn_dropout_rate=0\n",
    "args_bridge.cross_attn_num_heads=8\n",
    "args_bridge.res_input_dropout_rate=0.2\n",
    "args_bridge.res_layer_dropout_rate=0\n",
    "args_bridge.ff_input_dropout_rate=0.4\n",
    "args_bridge.ff_hidden_dropout_rate=0.0\n",
    "args_bridge.grad_norm=0.3\n",
    "args_bridge.decoding_algorithm=\"beam-search\"\n",
    "args_bridge.beam_size=8\n",
    "args_bridge.bs_alpha=1.0\n",
    "args_bridge.data_parallel=False\n",
    "\n",
    "args_bridge.model_dir = '../TabularSemanticParsing/model/wikisql.bridge.lstm.meta.ts.ko_from_table.bs_8.ppl-0.85.2.dn.no_from.feat.bert-base-multilingual-cased.xavier-768-512-512-8-3-0.0003-inv-sqr-0.0003-3000-5e-05-inv-sqr-0.0-3000-0.3-0.3-0.0-0.0-1-8-0.1-0.0-res-0.2-0.0-ff-0.4-0.0.test'\n",
    "\n",
    "sp = EncoderDecoderLFramework(args_bridge).cuda()\n",
    "\n",
    "sp.load_checkpoint(get_checkpoint_path(args_bridge))\n",
    "sp.eval()\n",
    "\n",
    "dataset = data_loader.load_processed_data(args_bridge)\n",
    "\n",
    "split = 'test'\n",
    "if args_bridge.dataset_name == 'wikisql':\n",
    "    engine_path = os.path.join(args_bridge.data_dir, '{}.db'.format(split))\n",
    "    engine = DBEngine(engine_path)\n",
    "else:\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2507a8",
   "metadata": {},
   "source": [
    "# Table information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_idx = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa859a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'][question_idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question with question_idx\n",
    "question = 'week 6에 얼마나 많은 팀이 뛰었을까?'\n",
    "dataset[split][question_idx].text = question\n",
    "\n",
    "examples = dataset[split][question_idx:question_idx+1]\n",
    "# examples = [question]\n",
    "sp.schema_graphs = dataset['schema']\n",
    "\n",
    "table_id = examples[0].db_name\n",
    "\n",
    "# define all tables\n",
    "with open('../TabularSemanticParsing/data/ko_from_table/test.tables.jsonl', 'r') as json_file:\n",
    "    tables = list(json_file)\n",
    "    \n",
    "for i, table in enumerate(tables):\n",
    "    tables[i] = ast.literal_eval(table)\n",
    "\n",
    "print('{} {} examples loaded'.format(len(examples), split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e16fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_restored_cache = sp.load_pred_restored_cache()\n",
    "pred_restored_cache_size = sum(len(v) for v in pred_restored_cache.values())\n",
    "\n",
    "out_dict = sp.inference(examples, restore_clause_order=args_bridge.process_sql_in_execution_order,\n",
    "                        pred_restored_cache=pred_restored_cache,\n",
    "                        check_schema_consistency_=args_bridge.sql_consistency_check,\n",
    "                        engine=engine, inline_eval=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sql = [out_dict['pred_decoded'][0][-1]]\n",
    "target_table = [table for table in tables if table[\"id\"] == table_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17433bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sql_q(pred_sql, target_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = pred_sql[0]['sel']\n",
    "agg = pred_sql[0]['agg']\n",
    "conds = pred_sql[0]['conds']\n",
    "\n",
    "engine.execute(table_id, sel, agg, conds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-attraction",
   "metadata": {},
   "source": [
    "# SPARTA (Semantic Parsing And Relational Table Aware)\n",
    "\n",
    "This is a term project in `Unstructured Text Analysis` class.   \n",
    "We implement the deep learning model for converting Korean language to SQL query. \n",
    "\n",
    "- github: https://github.com/TooTouch/SPARTA\n",
    "\n",
    "<br>\n",
    "<img src='https://user-images.githubusercontent.com/37654013/119700897-bec2c100-be8e-11eb-9d61-36de1ca66d5a.png'>\n",
    "<br>\n",
    "\n",
    "**Team Members**\n",
    "- Hoonsang Yoon \n",
    "- Jaehyuk Heo \n",
    "- Jungwoo Choi\n",
    "- Jeongseob Kim\n",
    "\n",
    "**Information**\n",
    "- Korea University [DSBA Lab](http://dsba.korea.ac.kr/)\n",
    "- Advisor: [Pilsung Kang](http://dsba.korea.ac.kr/professor/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "excessive-sierra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T07:49:52.145006Z",
     "start_time": "2021-06-07T07:49:51.172214Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append('../TabularSemanticParsing')\n",
    "# sys.path.extend(['../SQLova','../TabularSemanticParsing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a6966c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../TabularSemanticParsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "boolean-response",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T08:12:31.736868Z",
     "start_time": "2021-06-07T08:12:26.886118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* text vocab size = 119547\n",
      "* program vocab size = 99\n",
      "\n",
      "pretrained_transformer = bert-base-multilingual-cased\n",
      "fix_pretrained_transformer_parameters = False\n",
      "\n",
      "share_vocab is False\n",
      "bridge module created\n",
      "=> loading checkpoint '../TabularSemanticParsing/model/wikisql.bridge.lstm.meta.ts.ko_from_table.bs_8.ppl-0.85.2.dn.no_from.feat.bert-base-multilingual-cased.xavier-768-512-512-8-3-0.0003-inv-sqr-0.0003-3000-5e-05-inv-sqr-0.0-3000-0.3-0.3-0.0-0.0-1-8-0.1-0.0-res-0.2-0.0-ff-0.4-0.0.test/model-best.8.tar'\n",
      "loading preprocessed data: ../TabularSemanticParsing/data/ko_from_table/wikisql.bridge.question-split.ppl-0.85.2.dn.no_from.bert.multilingual.TabularSemanticParsing.pkl\n"
     ]
    }
   ],
   "source": [
    "# Bridge Model Define\n",
    "from src.semantic_parser.learn_framework import EncoderDecoderLFramework\n",
    "from src.semantic_parser.ensemble_configs import model_dirs as ensemble_model_dirs\n",
    "from src.eval.wikisql.lib.dbengine import DBEngine\n",
    "\n",
    "from src.demos.demos import Text2SQLWrapper\n",
    "from src.data_processor.path_utils import get_model_dir, get_checkpoint_path\n",
    "from src.data_processor.schema_graph import SchemaGraph\n",
    "from src.data_processor.vocab_processor import build_vocab\n",
    "from src.data_processor.data_processor import preprocess\n",
    "from src.data_processor.processors.data_processor_wikisql import generate_sql_q, generate_sql_q1\n",
    " \n",
    "import src.utils.utils as utils\n",
    "import src.eval.eval_tools as eval_tools\n",
    "\n",
    "import src.data_processor.processor_utils as data_utils\n",
    "import src.data_processor.data_loader as data_loader\n",
    "import src.common.ops as ops\n",
    "import random\n",
    "\n",
    "import ast\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# args_bridge = parser.parse_args(args=[])\n",
    "from src.parse_args import args as args_bridge\n",
    "\n",
    "args_bridge.data_dir=\"../TabularSemanticParsing/data/ko_from_table\"\n",
    "args_bridge.db_dir=\"../TabularSemanticParsing/data/ko_from_table\"\n",
    "args_bridge.dataset_name=\"wikisql\"\n",
    "args_bridge.model=\"bridge\"\n",
    "args_bridge.model_id = 2\n",
    "args_bridge.question_split=True\n",
    "args_bridge.query_split=False\n",
    "args_bridge.question_only=True\n",
    "args_bridge.normalize_variables=False\n",
    "args_bridge.denormalize_sql=True\n",
    "args_bridge.omit_from_clause=True\n",
    "args_bridge.table_shuffling=True\n",
    "args_bridge.use_graph_encoding=False\n",
    "args_bridge.use_typed_field_markers=False\n",
    "args_bridge.use_lstm_encoder=True\n",
    "args_bridge.use_meta_data_encoding=True\n",
    "args_bridge.use_picklist=True\n",
    "args_bridge.no_anchor_text=False\n",
    "args_bridge.anchor_text_match_threshold=0.85\n",
    "args_bridge.top_k_picklist_matches=2\n",
    "args_bridge.atomic_value_copy=False\n",
    "args_bridge.process_sql_in_execution_order=False\n",
    "args_bridge.sql_consistency_check=False\n",
    "args_bridge.share_vocab=False\n",
    "args_bridge.sample_ground_truth=False\n",
    "args_bridge.save_nn_weights_for_visualizations=True\n",
    "args_bridge.vocab_min_freq=0\n",
    "args_bridge.text_vocab_min_freq=0\n",
    "args_bridge.program_vocab_min_freq=0\n",
    "args_bridge.max_in_seq_len=512\n",
    "args_bridge.max_out_seq_len=60\n",
    "\n",
    "args_bridge.num_steps=10000\n",
    "args_bridge.curriculum_interval=0\n",
    "args_bridge.num_peek_steps=400\n",
    "args_bridge.num_accumulation_steps=3\n",
    "args_bridge.save_best_model_only=True\n",
    "args_bridge.train_batch_size=8\n",
    "args_bridge.dev_batch_size=8\n",
    "args_bridge.encoder_input_dim=768\n",
    "args_bridge.encoder_hidden_dim=512\n",
    "args_bridge.decoder_input_dim=512\n",
    "args_bridge.num_rnn_layers=1\n",
    "args_bridge.num_const_attn_layers=0\n",
    "args_bridge.use_oracle_tables=False\n",
    "args_bridge.num_random_tables_added=0\n",
    "args_bridge.use_additive_features=False\n",
    "args_bridge.schema_augmentation_factor=1\n",
    "args_bridge.random_field_order=False\n",
    "args_bridge.data_augmentation_factor=1\n",
    "args_bridge.augment_with_wikisql=False\n",
    "args_bridge.num_values_per_field=0\n",
    "args_bridge.pretrained_transformer=\"bert-base-multilingual-cased\"\n",
    "args_bridge.fix_pretrained_transformer_parameters=False\n",
    "args_bridge.bert_finetune_rate=0.00005\n",
    "args_bridge.learning_rate=0.0003\n",
    "args_bridge.learning_rate_scheduler=\"inverse-square\"\n",
    "args_bridge.trans_learning_rate_scheduler=\"inverse-square\"\n",
    "args_bridge.warmup_init_lr=0.0003\n",
    "args_bridge.warmup_init_ft_lr=0\n",
    "args_bridge.num_warmup_steps=3000\n",
    "args_bridge.emb_dropout_rate=0.3\n",
    "args_bridge.pretrained_lm_dropout_rate=0\n",
    "args_bridge.rnn_layer_dropout_rate=0.1\n",
    "args_bridge.rnn_weight_dropout_rate=0\n",
    "args_bridge.cross_attn_dropout_rate=0\n",
    "args_bridge.cross_attn_num_heads=8\n",
    "args_bridge.res_input_dropout_rate=0.2\n",
    "args_bridge.res_layer_dropout_rate=0\n",
    "args_bridge.ff_input_dropout_rate=0.4\n",
    "args_bridge.ff_hidden_dropout_rate=0.0\n",
    "args_bridge.grad_norm=0.3\n",
    "args_bridge.decoding_algorithm=\"beam-search\"\n",
    "args_bridge.beam_size=8\n",
    "args_bridge.bs_alpha=1.0\n",
    "args_bridge.data_parallel=False\n",
    "\n",
    "args_bridge.model_dir = '../TabularSemanticParsing/model/wikisql.bridge.lstm.meta.ts.ko_from_table.bs_8.ppl-0.85.2.dn.no_from.feat.bert-base-multilingual-cased.xavier-768-512-512-8-3-0.0003-inv-sqr-0.0003-3000-5e-05-inv-sqr-0.0-3000-0.3-0.3-0.0-0.0-1-8-0.1-0.0-res-0.2-0.0-ff-0.4-0.0.test'\n",
    "\n",
    "sp = EncoderDecoderLFramework(args_bridge).cuda()\n",
    "\n",
    "sp.load_checkpoint(get_checkpoint_path(args_bridge))\n",
    "sp.eval()\n",
    "\n",
    "dataset = data_loader.load_processed_data(args_bridge)\n",
    "\n",
    "split = 'test'\n",
    "if args_bridge.dataset_name == 'wikisql':\n",
    "    engine_path = os.path.join(args_bridge.data_dir, '{}.db'.format(split))\n",
    "    engine = DBEngine(engine_path)\n",
    "else:\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-remove",
   "metadata": {},
   "source": [
    "# Table information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "provincial-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_idx = 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "responsible-diversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'얼마나 많은 팀을 뛰었는지 week 6'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][question_idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "flying-mistress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test examples loaded\n"
     ]
    }
   ],
   "source": [
    "# Question with question_idx\n",
    "question = 'week 6에 얼마나 많은 팀이 뛰었을까?'\n",
    "dataset[split][question_idx].text = question\n",
    "\n",
    "examples = dataset[split][question_idx:question_idx+1]\n",
    "# examples = [question]\n",
    "sp.schema_graphs = dataset['schema']\n",
    "\n",
    "table_id = examples[0].db_name\n",
    "\n",
    "# define all tables\n",
    "with open('../TabularSemanticParsing/data/ko_from_table/test.tables.jsonl', 'r') as json_file:\n",
    "    tables = list(json_file)\n",
    "    \n",
    "for i, table in enumerate(tables):\n",
    "    tables[i] = ast.literal_eval(table)\n",
    "\n",
    "print('{} {} examples loaded'.format(len(examples), split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "logical-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_restored_cache = sp.load_pred_restored_cache()\n",
    "pred_restored_cache_size = sum(len(v) for v in pred_restored_cache.values())\n",
    "\n",
    "out_dict = sp.inference(examples, restore_clause_order=args_bridge.process_sql_in_execution_order,\n",
    "                        pred_restored_cache=pred_restored_cache,\n",
    "                        check_schema_consistency_=args_bridge.sql_consistency_check,\n",
    "                        engine=engine, inline_eval=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "located-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sql = [out_dict['pred_decoded'][0][-1]]\n",
    "target_table = [table for table in tables if table[\"id\"] == table_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "crazy-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELECT count(Opponent) FROM 1-11391448-2 WHERE Week = 6']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sql_q(pred_sql, target_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "beginning-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = pred_sql[0]['sel']\n",
    "agg = pred_sql[0]['agg']\n",
    "conds = pred_sql[0]['conds']\n",
    "\n",
    "engine.execute(table_id, sel, agg, conds)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

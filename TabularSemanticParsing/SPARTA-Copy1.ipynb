{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-attraction",
   "metadata": {},
   "source": [
    "# SPARTA (Semantic Parsing And Relational Table Aware)\n",
    "\n",
    "This is a term project in `Unstructured Text Analysis` class.   \n",
    "We implement the deep learning model for converting Korean language to SQL query. \n",
    "\n",
    "- github: https://github.com/TooTouch/SPARTA\n",
    "\n",
    "<br>\n",
    "<img src='https://user-images.githubusercontent.com/37654013/119700897-bec2c100-be8e-11eb-9d61-36de1ca66d5a.png'>\n",
    "<br>\n",
    "\n",
    "**Team Members**\n",
    "- Hoonsang Yoon \n",
    "- Jaehyuk Heo \n",
    "- Jungwoo Choi\n",
    "- Jeongseob Kim\n",
    "\n",
    "**Information**\n",
    "- Korea University [DSBA Lab](http://dsba.korea.ac.kr/)\n",
    "- Advisor: [Pilsung Kang](http://dsba.korea.ac.kr/professor/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excessive-sierra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:38:11.283955Z",
     "start_time": "2021-05-27T12:38:10.304582Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# from train import construct_hyper_param, \\\n",
    "#                   get_data, get_models, get_wemb_bert, \\\n",
    "#                   sort_and_generate_pr_w, generate_sql_q, \\\n",
    "#                   tokenize_corenlp_direct_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "plain-terry",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sqlova'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6dc7d3c738b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msqlova\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_wikisql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlova\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtopk_multi_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sqlova'"
     ]
    }
   ],
   "source": [
    "from sqlova.utils.utils_wikisql import *\n",
    "from sqlova.utils.utils import topk_multi_dim\n",
    "from sqlnet.dbengine import DBEngine\n",
    "\n",
    "import argparse\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ethical-europe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:38:12.115414Z",
     "start_time": "2021-05-27T12:38:12.087927Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cfc38ef7c73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = construct_hyper_param(parser, notebook=True)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "little-victory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:39:51.541906Z",
     "start_time": "2021-05-27T12:39:51.517748Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(inputs, engine, datadir, bert_config, model_bert, tokenizer):\n",
    "    nlu, nlu_t, hds, tb = inputs    \n",
    "    \n",
    "    # prediction\n",
    "    wemb_n, wemb_h, l_n, l_hpu, l_hs, \\\n",
    "    nlu_tt, t_to_tt_idx, tt_to_t_idx = get_wemb_bert(bert_config, \n",
    "                                                     model_bert, \n",
    "                                                     tokenizer, \n",
    "                                                     nlu_t, \n",
    "                                                     hds, \n",
    "                                                     args.max_seq_length,\n",
    "                                                     num_out_layers_n=args.num_target_layers, \n",
    "                                                     num_out_layers_h=args.num_target_layers,\n",
    "                                                     device=device)\n",
    "\n",
    "    prob_sca, prob_w, prob_wn_w, pr_sc, pr_sa, pr_wn, pr_sql_i, pr_sql_topk_i = model.beam_forward(wemb_n, \n",
    "                                                                                                   l_n, \n",
    "                                                                                                   wemb_h, \n",
    "                                                                                                   l_hpu,\n",
    "                                                                                                   l_hs, \n",
    "                                                                                                   engine, \n",
    "                                                                                                   tb,\n",
    "                                                                                                   nlu_t, \n",
    "                                                                                                   nlu_tt,\n",
    "                                                                                                   tt_to_t_idx, \n",
    "                                                                                                   nlu,\n",
    "                                                                                                   beam_size=args.beam_size,\n",
    "                                                                                                   device=device)\n",
    "\n",
    "    pr_wc, pr_wo, pr_wv, pr_sql_i = sort_and_generate_pr_w(pr_sql_i)\n",
    "\n",
    "    pr_sql_q1 = generate_sql_q(pr_sql_i, tb)[0]\n",
    "    pr_ans = engine.execute(tb[0]['id'], \n",
    "                            pr_sc[0], \n",
    "                            pr_sa[0], \n",
    "                            pr_sql_i[0]['conds'])\n",
    "    \n",
    "    return pr_sql_q1, pr_ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bright-firewall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:39:52.383988Z",
     "start_time": "2021-05-27T12:39:52.362150Z"
    }
   },
   "outputs": [],
   "source": [
    "args.datadir = '../data/ko_from_table'\n",
    "args.logdir = '../logs/ko_from_table'\n",
    "args.bert_name = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mediterranean-florist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:40:04.544893Z",
     "start_time": "2021-05-27T12:39:52.588418Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ad4fd351431b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# To start from the pre-trained models, un-comment following lines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_model_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_bert_best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "_, _, _, _, test_data, test_table, _, _, test_loader = get_data(args.datadir, args)\n",
    "\n",
    "\n",
    "# To start from the pre-trained models, un-comment following lines.\n",
    "path_model_bert = os.path.join(args.logdir, 'model_bert_best.pt')\n",
    "path_model = os.path.join(args.logdir, 'model_best.pt')\n",
    "model, model_bert, tokenizer, bert_config = get_models(args, \n",
    "                                                       trained=True,\n",
    "                                                       path_model_bert=path_model_bert, \n",
    "                                                       path_model=path_model, \n",
    "                                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elementary-minneapolis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:40:04.568170Z",
     "start_time": "2021-05-27T12:40:04.546083Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fd32abddb0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "engine = DBEngine(os.path.join(args.datadir, 'test.db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-remove",
   "metadata": {},
   "source": [
    "# Table information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "center-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_label(idx):\n",
    "    \n",
    "    tb = [test_table[test_data[idx]['table_id']]]\n",
    "    hds = [tb[0]['header']]\n",
    "    nlu_t = [test_data[idx]['question_tok']]\n",
    "    nlu = [test_data[idx]['question']]\n",
    "    sql = [test_data[idx]['sql']]\n",
    "\n",
    "    # sql\n",
    "    g_sql = generate_sql_q(sql, tb)[0]\n",
    "\n",
    "    from_start_idx = g_sql.find('FROM')\n",
    "    where_start_idx = g_sql.find('WHERE')\n",
    "    if where_start_idx == -1:\n",
    "        g_sql = g_sql[:from_start_idx] + '\\n' + g_sql[from_start_idx:]\n",
    "    else:\n",
    "        g_sql = g_sql[:from_start_idx] + '\\n' + g_sql[from_start_idx:where_start_idx] + '\\n' + g_sql[where_start_idx:]\n",
    "\n",
    "    # answer\n",
    "    g_ans  = engine.execute(tb[0]['id'], \n",
    "                            sql[0]['sel'], \n",
    "                            sql[0]['agg'], \n",
    "                            sql[0]['conds'])[0]\n",
    "\n",
    "    # plotting\n",
    "    display(pd.DataFrame(tb[0]['rows'], columns=tb[0]['header']))\n",
    "\n",
    "    print('='*20)\n",
    "    print('Ground Truth')\n",
    "    print('='*20)\n",
    "    print('[Question]')\n",
    "    print(nlu[0])\n",
    "    print()\n",
    "    print('[SQL]')\n",
    "    print(g_sql)\n",
    "    print()\n",
    "    print('[RESULT]')\n",
    "    print(g_ans)\n",
    "    print('='*20)\n",
    "    \n",
    "    # inference\n",
    "    display(ipywidgets.HTML('<h1>Inference</h1>'))\n",
    "    question = ipywidgets.Text(description='QUESTION:', \n",
    "                           layout=ipywidgets.Layout(width='auto', display='flex'))\n",
    "    button = ipywidgets.Button(description='TEST')\n",
    "    output = ipywidgets.Output()\n",
    "    display(ipywidgets.VBox([question, button]))\n",
    "    display(output)\n",
    "    \n",
    "    def infer(b):\n",
    "        q_tokenizer = Mecab()\n",
    "        question_t = q_tokenizer.morphs(question.value)\n",
    "\n",
    "        pr_sql_q1, pr_ans = inference(inputs=[[question.value], [question_t], hds, tb], \n",
    "                                      engine=engine,\n",
    "                                      datadir=args.datadir, \n",
    "                                      bert_config=bert_config, \n",
    "                                      model_bert=model_bert, \n",
    "                                      tokenizer=tokenizer)\n",
    "    \n",
    "        # print results\n",
    "        from_start_idx = pr_sql_q1.find('FROM')\n",
    "        where_start_idx = pr_sql_q1.find('WHERE')\n",
    "        if where_start_idx == -1:\n",
    "            pr_sql_q1 = pr_sql_q1[:from_start_idx] + '\\n' + pr_sql_q1[from_start_idx:]\n",
    "        else:\n",
    "            pr_sql_q1 = pr_sql_q1[:from_start_idx] + '\\n' + pr_sql_q1[from_start_idx:where_start_idx] + '\\n' + pr_sql_q1[where_start_idx:]\n",
    "        \n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print('='*20)\n",
    "            print('Inference')\n",
    "            print('='*20)\n",
    "            print('[SQL]')\n",
    "            print(pr_sql_q1)\n",
    "            print()\n",
    "            print('[RESULT]')\n",
    "            for ans in pr_ans:\n",
    "                print(ans)\n",
    "            print('='*20)\n",
    "    \n",
    "    button.on_click(infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "racial-specialist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:25:47.594853Z",
     "start_time": "2021-05-27T13:25:47.564802Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_table_label(idx):\n",
    "    \n",
    "    tb = [test_table[test_data[idx]['table_id']]]\n",
    "    hds = [tb[0]['header']]\n",
    "    nlu_t = [test_data[idx]['question_tok']]\n",
    "    nlu = [test_data[idx]['question']]\n",
    "    sql = [test_data[idx]['sql']]\n",
    "\n",
    "    # sql\n",
    "    g_sql = generate_sql_q(sql, tb)[0]\n",
    "\n",
    "    from_start_idx = g_sql.find('FROM')\n",
    "    where_start_idx = g_sql.find('WHERE')\n",
    "    if where_start_idx == -1:\n",
    "        g_sql = g_sql[:from_start_idx] + '\\n' + g_sql[from_start_idx:]\n",
    "    else:\n",
    "        g_sql = g_sql[:from_start_idx] + '\\n' + g_sql[from_start_idx:where_start_idx] + '\\n' + g_sql[where_start_idx:]\n",
    "\n",
    "    # answer\n",
    "    g_ans  = engine.execute(tb[0]['id'], \n",
    "                            sql[0]['sel'], \n",
    "                            sql[0]['agg'], \n",
    "                            sql[0]['conds'])[0]\n",
    "\n",
    "    # plotting\n",
    "    display(pd.DataFrame(tb[0]['rows'], columns=tb[0]['header']))\n",
    "\n",
    "    print('='*20)\n",
    "    print('Ground Truth')\n",
    "    print('='*20)\n",
    "    print('[Question]')\n",
    "    print(nlu[0])\n",
    "    print()\n",
    "    print('[SQL]')\n",
    "    print(g_sql)\n",
    "    print()\n",
    "    print('[RESULT]')\n",
    "    print(g_ans)\n",
    "    print('='*20)\n",
    "    \n",
    "    # inference\n",
    "    display(ipywidgets.HTML('<h1>Inference</h1>'))\n",
    "    question = ipywidgets.Text(description='QUESTION:', \n",
    "                           layout=ipywidgets.Layout(width='auto', display='flex'))\n",
    "    button = ipywidgets.Button(description='TEST')\n",
    "    output = ipywidgets.Output()\n",
    "    display(ipywidgets.VBox([question, button]))\n",
    "    display(output)\n",
    "    \n",
    "    def infer(b):\n",
    "        q_tokenizer = Mecab()\n",
    "        question_t = q_tokenizer.morphs(question.value)\n",
    "\n",
    "        pr_sql_q1, pr_ans = inference(inputs=[[question.value], [question_t], hds, tb], \n",
    "                                      engine=engine,\n",
    "                                      datadir=args.datadir, \n",
    "                                      bert_config=bert_config, \n",
    "                                      model_bert=model_bert, \n",
    "                                      tokenizer=tokenizer)\n",
    "    \n",
    "        # print results\n",
    "        from_start_idx = pr_sql_q1.find('FROM')\n",
    "        where_start_idx = pr_sql_q1.find('WHERE')\n",
    "        if where_start_idx == -1:\n",
    "            pr_sql_q1 = pr_sql_q1[:from_start_idx] + '\\n' + pr_sql_q1[from_start_idx:]\n",
    "        else:\n",
    "            pr_sql_q1 = pr_sql_q1[:from_start_idx] + '\\n' + pr_sql_q1[from_start_idx:where_start_idx] + '\\n' + pr_sql_q1[where_start_idx:]\n",
    "        \n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            print('='*20)\n",
    "            print('Inference')\n",
    "            print('='*20)\n",
    "            print('[SQL]')\n",
    "            print(pr_sql_q1)\n",
    "            print()\n",
    "            print('[RESULT]')\n",
    "            for ans in pr_ans:\n",
    "                print(ans)\n",
    "            print('='*20)\n",
    "    \n",
    "    button.on_click(infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "female-robinson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:03:54.272162Z",
     "start_time": "2021-05-27T13:03:54.244974Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ipywidgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3e72dd271f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m index_text = ipywidgets.BoundedIntText(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ipywidgets' is not defined"
     ]
    }
   ],
   "source": [
    "index_text = ipywidgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(test_data),\n",
    "    step=1,\n",
    "    description='INDEX:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "designed-illustration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:03:54.474093Z",
     "start_time": "2021-05-27T13:03:54.385816Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f556aa89806544688417496666d068f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=0, description='INDEX:', max=15878), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipywidgets.interactive(print_table_label, idx=index_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-dressing",
   "metadata": {},
   "source": [
    "# Bridge Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "colonial-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.utils as utils\n",
    "from src.semantic_parser.learn_framework import EncoderDecoderLFramework\n",
    "from src.semantic_parser.ensemble_configs import model_dirs as ensemble_model_dirs\n",
    "from src.eval.wikisql.lib.dbengine import DBEngine\n",
    "import src.eval.eval_tools as eval_tools\n",
    "from src.demos.demos import Text2SQLWrapper\n",
    "from src.data_processor.path_utils import get_model_dir, get_checkpoint_path\n",
    "from src.data_processor.schema_graph import SchemaGraph\n",
    "from src.data_processor.vocab_processor import build_vocab\n",
    "from src.data_processor.data_processor import preprocess\n",
    "import src.data_processor.processor_utils as data_utils\n",
    "import src.data_processor.data_loader as data_loader\n",
    "import src.common.ops as ops\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from src.parse_args import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_dir=\"data/ko_token\"\n",
    "args.db_dir=\"data/ko_token\"\n",
    "args.dataset_name=\"wikisql\"\n",
    "args.model=\"bridge\"\n",
    "args.model_id = 2\n",
    "args.question_split=True\n",
    "args.query_split=False\n",
    "args.question_only=True\n",
    "args.normalize_variables=False\n",
    "args.denormalize_sql=True\n",
    "args.omit_from_clause=True\n",
    "args.no_join_condition=False\n",
    "args.table_shuffling=True\n",
    "args.use_graph_encoding=False\n",
    "args.use_typed_field_markers=False\n",
    "args.use_lstm_encoder=True\n",
    "args.use_meta_data_encoding=True\n",
    "args.use_picklist=True\n",
    "args.no_anchor_text=False\n",
    "args.anchor_text_match_threshold=0.85\n",
    "args.top_k_picklist_matches=2\n",
    "args.atomic_value_copy=False\n",
    "args.process_sql_in_execution_order=False\n",
    "args.sql_consistency_check=False\n",
    "args.share_vocab=False\n",
    "args.sample_ground_truth=False\n",
    "args.save_nn_weights_for_visualizations=True\n",
    "args.vocab_min_freq=0\n",
    "args.text_vocab_min_freq=0\n",
    "args.program_vocab_min_freq=0\n",
    "args.max_in_seq_len=512\n",
    "args.max_out_seq_len=60\n",
    "\n",
    "args.num_steps=10000\n",
    "args.curriculum_interval=0\n",
    "args.num_peek_steps=400\n",
    "args.num_accumulation_steps=3\n",
    "args.save_best_model_only=True\n",
    "args.train_batch_size=8\n",
    "args.dev_batch_size=8\n",
    "args.encoder_input_dim=768\n",
    "args.encoder_hidden_dim=512\n",
    "args.decoder_input_dim=512\n",
    "args.num_rnn_layers=1\n",
    "args.num_const_attn_layers=0\n",
    "args.use_oracle_tables=False\n",
    "args.num_random_tables_added=0\n",
    "args.use_additive_features=False\n",
    "args.schema_augmentation_factor=1\n",
    "args.random_field_order=False\n",
    "args.data_augmentation_factor=1\n",
    "args.augment_with_wikisql=False\n",
    "args.num_values_per_field=0\n",
    "args.pretrained_transformer=\"bert-base-multilingual-cased\"\n",
    "args.fix_pretrained_transformer_parameters=False\n",
    "args.bert_finetune_rate=0.00005\n",
    "args.learning_rate=0.0003\n",
    "args.learning_rate_scheduler=\"inverse-square\"\n",
    "args.trans_learning_rate_scheduler=\"inverse-square\"\n",
    "args.warmup_init_lr=0.0003\n",
    "args.warmup_init_ft_lr=0\n",
    "args.num_warmup_steps=3000\n",
    "args.emb_dropout_rate=0.3\n",
    "args.pretrained_lm_dropout_rate=0\n",
    "args.rnn_layer_dropout_rate=0.1\n",
    "args.rnn_weight_dropout_rate=0\n",
    "args.cross_attn_dropout_rate=0\n",
    "args.cross_attn_num_heads=8\n",
    "args.res_input_dropout_rate=0.2\n",
    "args.res_layer_dropout_rate=0\n",
    "args.ff_input_dropout_rate=0.4\n",
    "args.ff_hidden_dropout_rate=0.0\n",
    "args.grad_norm=0.3\n",
    "args.decoding_algorithm=\"beam-search\"\n",
    "args.beam_size=8\n",
    "args.bs_alpha=1.0\n",
    "args.data_parallel=False\n",
    "\n",
    "args.model_dir = './model/wikisql.bridge.lstm.meta.ts.ko_token.bs_8.ppl-0.85.2.dn.no_from.feat.bert-base-multilingual-cased.xavier-768-512-512-8-3-0.0003-inv-sqr-0.0003-3000-5e-05-inv-sqr-0.0-3000-0.3-0.3-0.0-0.0-1-8-0.1-0.0-res-0.2-0.0-ff-0.4-0.0.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* text vocab size = 119547\n",
      "* program vocab size = 99\n",
      "\n",
      "pretrained_transformer = bert-base-multilingual-cased\n",
      "fix_pretrained_transformer_parameters = False\n",
      "\n",
      "share_vocab is False\n",
      "bridge module created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoonst/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './model/wikisql.bridge.lstm.meta.ts.ko_token.bs_8.ppl-0.85.2.dn.no_from.feat.bert-base-multilingual-cased.xavier-768-512-512-8-3-0.0003-inv-sqr-0.0003-3000-5e-05-inv-sqr-0.0-3000-0.3-0.3-0.0-0.0-1-8-0.1-0.0-res-0.2-0.0-ff-0.4-0.0.test/model-best.8.tar'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderLFramework(\n",
       "  (mdl): Bridge(\n",
       "    (encoder_embeddings): TransformerHiddens(\n",
       "      (trans_parameters): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (decoder_embeddings): Embedding(\n",
       "      (embeddings): Embedding(99, 512)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): SchemaAwareTransformerEncoder(\n",
       "      (bilstm_encoder): RNNEncoder(\n",
       "        (rnn): LSTMWithPacking(\n",
       "          (rnn): WeightDropoutLSTM(\n",
       "            (rnn): LSTM(768, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (text_encoder): RNNEncoder(\n",
       "        (rnn): LSTMWithPacking(\n",
       "          (rnn): WeightDropoutLSTM(\n",
       "            (rnn): LSTM(512, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (schema_encoder): SchemaEncoder(\n",
       "        (primary_key_embeddings): Embedding(\n",
       "          (embeddings): Embedding(2, 512)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (foreign_key_embeddings): Embedding(\n",
       "          (embeddings): Embedding(2, 512)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (field_type_embeddings): Embedding(\n",
       "          (embeddings): Embedding(6, 512)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (feature_fusion_layer): Feedforward(\n",
       "          (input_dropout): Dropout(p=0.4, inplace=False)\n",
       "          (hidden_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (field_table_fusion_layer): FusionLayer(\n",
       "          (res_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_dropout): Dropout(p=0, inplace=False)\n",
       "          (layer_norm): LayerNorm()\n",
       "          (res_feed_forward): ResidualBlock(\n",
       "            (mdl_with_residual_connection): ResidualConnectionWrapper(\n",
       "              (mdl): Feedforward(\n",
       "                (input_dropout): Dropout(p=0.4, inplace=False)\n",
       "                (hidden_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (res_dropout): Dropout(p=0.2, inplace=False)\n",
       "              (layer_dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "            (layer_norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): BridgeDecoder(\n",
       "      (out): LogSoftmaxOutput(\n",
       "        (linear): Linear(in_features=512, out_features=99, bias=True)\n",
       "        (log_softmax): LogSoftmax(dim=-1)\n",
       "      )\n",
       "      (rnn): WeightDropoutLSTM(\n",
       "        (rnn): LSTM(1024, 512, batch_first=True, dropout=0.1)\n",
       "      )\n",
       "      (attn): MultiHead(\n",
       "        (attention): AttentionDotProduct(\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (wq): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wk): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wv): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wo): Linear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (attn_combine): ConcatAndProject(\n",
       "        (input_dropout): Dropout(p=0.4, inplace=False)\n",
       "        (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      )\n",
       "      (pointer_switch): PointerSwitch(\n",
       "        (project): ConcatAndProject(\n",
       "          (input_dropout): Dropout(p=0.4, inplace=False)\n",
       "          (linear1): Linear(in_features=1024, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fun): MaskedCrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = EncoderDecoderLFramework(args).cuda()\n",
    "\n",
    "sp.load_checkpoint(get_checkpoint_path(args))\n",
    "sp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "functional-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed data: data/ko_token/wikisql.bridge.question-split.ppl-0.85.2.dn.no_from.bert.multilingual.ko_token.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset = data_loader.load_processed_data(args)\n",
    "\n",
    "split = 'test'\n",
    "if args.dataset_name == 'wikisql':\n",
    "    engine_path = os.path.join(args.data_dir, '{}.db'.format(split))\n",
    "    engine = DBEngine(engine_path)\n",
    "else:\n",
    "    engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_idx = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wanted-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'초안에 LB이있는 college는 무엇입니까?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][question_idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "given-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expanded-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test examples loaded\n"
     ]
    }
   ],
   "source": [
    "# Question with question_idx\n",
    "question = '초안에 LB college가 뭐냐?'\n",
    "dataset['test'][question_idx].text = question\n",
    "\n",
    "examples = dataset[split][question_idx:question_idx+1]\n",
    "sp.schema_graphs = dataset['schema']\n",
    "\n",
    "table_id = examples[0].db_name\n",
    "\n",
    "# define all tables\n",
    "with open('./data/ko_from_table/test.tables.jsonl', 'r') as json_file:\n",
    "    tables = list(json_file)\n",
    "    \n",
    "for i, table in enumerate(tables):\n",
    "    tables[i] = ast.literal_eval(table)\n",
    "\n",
    "print('{} {} examples loaded'.format(len(examples), split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tight-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_restored_cache = sp.load_pred_restored_cache()\n",
    "pred_restored_cache_size = sum(len(v) for v in pred_restored_cache.values())\n",
    "\n",
    "out_dict = sp.inference(examples, restore_clause_order=args.process_sql_in_execution_order,\n",
    "                            pred_restored_cache=pred_restored_cache,\n",
    "                            check_schema_consistency_=args.sql_consistency_check,\n",
    "                            engine=engine, inline_eval=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amended-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sql = [out_dict['pred_decoded'][0][-1]]\n",
    "target_table = [table for table in tables if table[\"id\"] == table_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increasing-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processor.processors.data_processor_wikisql import generate_sql_q, generate_sql_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interstate-aquatic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELECT (College) FROM 1-10812403-4 WHERE Position = LB']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sql_q(pred_sql, target_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "excellent-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laval']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = pred_sql[0]['sel']\n",
    "agg = pred_sql[0]['agg']\n",
    "conds = pred_sql[0]['conds']\n",
    "\n",
    "engine.execute(table_id, sel, agg, conds)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

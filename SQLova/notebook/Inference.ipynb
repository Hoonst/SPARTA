{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excessive-sierra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:12.248082Z",
     "start_time": "2021-05-09T04:06:11.132060Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import os \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from train import construct_hyper_param, \\\n",
    "                  get_data, get_models, get_wemb_bert, \\\n",
    "                  sort_and_generate_pr_w, generate_sql_q, \\\n",
    "                  tokenize_corenlp_direct_version\n",
    "from sqlova.utils.utils_wikisql import *\n",
    "from sqlova.utils.utils import topk_multi_dim\n",
    "from sqlnet.dbengine import DBEngine\n",
    "\n",
    "import corenlp\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-europe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:13.045629Z",
     "start_time": "2021-05-09T04:06:12.986676Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = construct_hyper_param(parser, notebook=True)\n",
    "\n",
    "# gpu\n",
    "# args.gpu = 1\n",
    "\n",
    "# GPU_NUM = args.gpu # select gpu number\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "# print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-victory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:14.548840Z",
     "start_time": "2021-05-09T04:06:14.524058Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(inputs, sql, datadir, bert_config, model_bert, tokenizer):\n",
    "    nlu, nlu_t, hds, tb = inputs\n",
    "    \n",
    "    \n",
    "    engine = DBEngine(os.path.join(datadir, 'test.db'))\n",
    "    \n",
    "    # prediction\n",
    "    wemb_n, wemb_h, l_n, l_hpu, l_hs, \\\n",
    "    nlu_tt, t_to_tt_idx, tt_to_t_idx = get_wemb_bert(bert_config, \n",
    "                                                     model_bert, \n",
    "                                                     tokenizer, \n",
    "                                                     nlu_t, \n",
    "                                                     hds, \n",
    "                                                     args.max_seq_length,\n",
    "                                                     num_out_layers_n=args.num_target_layers, \n",
    "                                                     num_out_layers_h=args.num_target_layers,\n",
    "                                                     device=device)\n",
    "\n",
    "    prob_sca, prob_w, prob_wn_w, pr_sc, pr_sa, pr_wn, pr_sql_i = model.beam_forward(wemb_n, \n",
    "                                                                                    l_n, \n",
    "                                                                                    wemb_h, \n",
    "                                                                                    l_hpu,\n",
    "                                                                                    l_hs, \n",
    "                                                                                    engine, \n",
    "                                                                                    tb,\n",
    "                                                                                    nlu_t, \n",
    "                                                                                    nlu_tt,\n",
    "                                                                                    tt_to_t_idx, \n",
    "                                                                                    nlu,\n",
    "                                                                                    beam_size=args.beam_size,\n",
    "                                                                                    device=device)\n",
    "\n",
    "    pr_wc, pr_wo, pr_wv, pr_sql_i = sort_and_generate_pr_w(pr_sql_i)\n",
    "\n",
    "    pr_sql_q1 = generate_sql_q(pr_sql_i, tb)\n",
    "    pr_ans, _ = engine.execute_return_query(tb[0]['id'], pr_sc[0], pr_sa[0], pr_sql_i[0]['conds'])\n",
    "    \n",
    "    # ground truth\n",
    "    g_sql_q1 = generate_sql_q(sql, tb)\n",
    "\n",
    "    g_ans, _ = engine.execute_return_query(tb[0]['id'], \n",
    "                                           sql[0]['sel'], \n",
    "                                           sql[0]['agg'], \n",
    "                                           sql[0]['conds'])\n",
    "    \n",
    "    # print results\n",
    "    print()\n",
    "    print('='*30)\n",
    "    print('Logical Form')\n",
    "    print('='*30)\n",
    "    print('[PRED]: ',pr_sql_q1[0])\n",
    "    print('[TRUE]: ',g_sql_q1[0])\n",
    "    print()\n",
    "    print('='*30)\n",
    "    print('Execution')\n",
    "    print('='*30)\n",
    "    print('[PRED]: ',pr_ans[0])\n",
    "    print('[TRUE]: ',g_ans[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-zambia",
   "metadata": {},
   "source": [
    "# Testset Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facial-dairy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T07:26:46.788343Z",
     "start_time": "2021-05-07T07:26:46.729273Z"
    }
   },
   "outputs": [],
   "source": [
    "lognames = ['ko_token','ko_from_table']\n",
    "result_lst = []\n",
    "\n",
    "for name in lognames:\n",
    "    file = json.load(open(f'../logs/{name}/dev_performance.json','r'))\n",
    "    result_lst.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eight-absence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T07:26:46.849144Z",
     "start_time": "2021-05-07T07:26:46.789591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc_sc</th>\n",
       "      <th>acc_sa</th>\n",
       "      <th>acc_wn</th>\n",
       "      <th>acc_wc</th>\n",
       "      <th>acc_wo</th>\n",
       "      <th>acc_wvi</th>\n",
       "      <th>acc_wv</th>\n",
       "      <th>acc_lx</th>\n",
       "      <th>acc_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ko_token</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ko_from_table</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss  acc_sc  acc_sa  acc_wn  acc_wc  acc_wo  acc_wvi  acc_wv  \\\n",
       "ko_token        0.0   0.898   0.870   0.919   0.862   0.878      0.0   0.872   \n",
       "ko_from_table   0.0   0.869   0.868   0.913   0.866   0.880      0.0   0.874   \n",
       "\n",
       "               acc_lx  acc_x  \n",
       "ko_token        0.702  0.781  \n",
       "ko_from_table   0.702  0.773  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([list(result_lst[i].values()) for i in range(len(lognames))]), \n",
    "             columns=result_lst[0].keys(),\n",
    "             index=lognames).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-maker",
   "metadata": {},
   "source": [
    "# Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bright-firewall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:18.990071Z",
     "start_time": "2021-05-09T04:06:18.958317Z"
    }
   },
   "outputs": [],
   "source": [
    "args.datadir = '../data/ko_token'\n",
    "args.logdir = '../logs/ko_token'\n",
    "args.bert_name = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mediterranean-florist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:30.693298Z",
     "start_time": "2021-05-09T04:06:19.439369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT: pretrained bert-base-multilingual-cased\n",
      "BERT: learning rate: 1e-05\n",
      "BERT: Fine-tune BERT: False\n",
      "Seq-to-SQL: the number of final BERT layers to be used: 2\n",
      "Seq-to-SQL: the size of hidden dimension = 100\n",
      "Seq-to-SQL: LSTM encoding layer size = 2\n",
      "Seq-to-SQL: dropout rate = 0.3\n",
      "Seq-to-SQL: learning rate = 0.001\n"
     ]
    }
   ],
   "source": [
    "train_data, train_table, dev_data, dev_table, test_data, test_table, _, _, test_loader = get_data(args.datadir, args)\n",
    "\n",
    "\n",
    "# To start from the pre-trained models, un-comment following lines.\n",
    "path_model_bert = os.path.join(args.logdir, 'model_bert_best.pt')\n",
    "path_model = os.path.join(args.logdir, 'model_best.pt')\n",
    "model, model_bert, tokenizer, bert_config = get_models(args, \n",
    "                                                       trained=True,\n",
    "                                                       path_model_bert=path_model_bert, \n",
    "                                                       path_model=path_model, \n",
    "                                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "invisible-insertion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T07:27:00.028179Z",
     "start_time": "2021-05-07T07:27:00.012187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. in series</th>\n",
       "      <th>No. in season</th>\n",
       "      <th>Title</th>\n",
       "      <th>Directed by</th>\n",
       "      <th>Written by</th>\n",
       "      <th>Featured character(s)</th>\n",
       "      <th>Original air date</th>\n",
       "      <th>U.S. viewers (million)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104/105</td>\n",
       "      <td>1/2</td>\n",
       "      <td>\" LA X \"</td>\n",
       "      <td>Jack Bender</td>\n",
       "      <td>Damon Lindelof &amp; Carlton Cuse</td>\n",
       "      <td>Various</td>\n",
       "      <td>February2,2010</td>\n",
       "      <td>12.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>\" What Kate Does \"</td>\n",
       "      <td>Paul Edwards</td>\n",
       "      <td>Edward Kitsis &amp; Adam Horowitz</td>\n",
       "      <td>Kate</td>\n",
       "      <td>February9,2010</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>\" The Substitute \"</td>\n",
       "      <td>Tucker Gates</td>\n",
       "      <td>Elizabeth Sarnoff &amp; Melinda Hsu Taylor</td>\n",
       "      <td>Locke</td>\n",
       "      <td>February16,2010</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>\" Lighthouse \"</td>\n",
       "      <td>Jack Bender</td>\n",
       "      <td>Carlton Cuse &amp; Damon Lindelof</td>\n",
       "      <td>Jack</td>\n",
       "      <td>February23,2010</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "      <td>\" Sundown \"</td>\n",
       "      <td>Bobby Roth</td>\n",
       "      <td>Paul Zbyszewski &amp; Graham Roland</td>\n",
       "      <td>Sayid</td>\n",
       "      <td>March2,2010</td>\n",
       "      <td>9.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>\" Dr. Linus \"</td>\n",
       "      <td>Mario Van Peebles</td>\n",
       "      <td>Edward Kitsis &amp; Adam Horowitz</td>\n",
       "      <td>Ben</td>\n",
       "      <td>March9,2010</td>\n",
       "      <td>9.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>8</td>\n",
       "      <td>\" Recon \"</td>\n",
       "      <td>Jack Bender</td>\n",
       "      <td>Elizabeth Sarnoff &amp; Jim Galasso</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>March16,2010</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112</td>\n",
       "      <td>9</td>\n",
       "      <td>\" Ab Aeterno \"</td>\n",
       "      <td>Tucker Gates</td>\n",
       "      <td>Melinda Hsu Taylor &amp; Greggory Nations</td>\n",
       "      <td>Richard</td>\n",
       "      <td>March23,2010</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113</td>\n",
       "      <td>10</td>\n",
       "      <td>\" The Package \"</td>\n",
       "      <td>Paul Edwards</td>\n",
       "      <td>Paul Zbyszewski &amp; Graham Roland</td>\n",
       "      <td>Sun &amp; Jin</td>\n",
       "      <td>March30,2010</td>\n",
       "      <td>10.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114</td>\n",
       "      <td>11</td>\n",
       "      <td>\" Happily Ever After \"</td>\n",
       "      <td>Jack Bender</td>\n",
       "      <td>Carlton Cuse &amp; Damon Lindelof</td>\n",
       "      <td>Desmond</td>\n",
       "      <td>April6,2010</td>\n",
       "      <td>9.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>115</td>\n",
       "      <td>12</td>\n",
       "      <td>\" Everybody Loves Hugo \"</td>\n",
       "      <td>Daniel Attias</td>\n",
       "      <td>Edward Kitsis &amp; Adam Horowitz</td>\n",
       "      <td>Hurley</td>\n",
       "      <td>April13,2010</td>\n",
       "      <td>9.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>116</td>\n",
       "      <td>13</td>\n",
       "      <td>\" The Last Recruit \"</td>\n",
       "      <td>Stephen Semel</td>\n",
       "      <td>Paul Zbyszewski &amp; Graham Roland</td>\n",
       "      <td>Various</td>\n",
       "      <td>April20,2010</td>\n",
       "      <td>9.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>117</td>\n",
       "      <td>14</td>\n",
       "      <td>\" The Candidate \"</td>\n",
       "      <td>Jack Bender</td>\n",
       "      <td>Elizabeth Sarnoff &amp; Jim Galasso</td>\n",
       "      <td>Jack &amp; Locke</td>\n",
       "      <td>May4,2010</td>\n",
       "      <td>9.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>118</td>\n",
       "      <td>15</td>\n",
       "      <td>\" Across the Sea \"</td>\n",
       "      <td>Tucker Gates</td>\n",
       "      <td>Carlton Cuse &amp; Damon Lindelof</td>\n",
       "      <td>Jacob &amp; Man in Black</td>\n",
       "      <td>May11,2010</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>\" What They Died For \"</td>\n",
       "      <td>Paul Edwards</td>\n",
       "      <td>Edward Kitsis, Adam Horowitz &amp; Elizabeth Sarnoff</td>\n",
       "      <td>Various</td>\n",
       "      <td>May18,2010</td>\n",
       "      <td>10.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. in series No. in season                     Title        Directed by  \\\n",
       "0        104/105           1/2                  \" LA X \"        Jack Bender   \n",
       "1            106             3        \" What Kate Does \"       Paul Edwards   \n",
       "2            107             4        \" The Substitute \"       Tucker Gates   \n",
       "3            108             5            \" Lighthouse \"        Jack Bender   \n",
       "4            109             6               \" Sundown \"         Bobby Roth   \n",
       "5            110             7             \" Dr. Linus \"  Mario Van Peebles   \n",
       "6            111             8                 \" Recon \"        Jack Bender   \n",
       "7            112             9            \" Ab Aeterno \"       Tucker Gates   \n",
       "8            113            10           \" The Package \"       Paul Edwards   \n",
       "9            114            11    \" Happily Ever After \"        Jack Bender   \n",
       "10           115            12  \" Everybody Loves Hugo \"      Daniel Attias   \n",
       "11           116            13      \" The Last Recruit \"      Stephen Semel   \n",
       "12           117            14         \" The Candidate \"        Jack Bender   \n",
       "13           118            15        \" Across the Sea \"       Tucker Gates   \n",
       "14           119            16    \" What They Died For \"       Paul Edwards   \n",
       "\n",
       "                                          Written by Featured character(s)  \\\n",
       "0                      Damon Lindelof & Carlton Cuse               Various   \n",
       "1                      Edward Kitsis & Adam Horowitz                  Kate   \n",
       "2             Elizabeth Sarnoff & Melinda Hsu Taylor                 Locke   \n",
       "3                      Carlton Cuse & Damon Lindelof                  Jack   \n",
       "4                    Paul Zbyszewski & Graham Roland                 Sayid   \n",
       "5                      Edward Kitsis & Adam Horowitz                   Ben   \n",
       "6                    Elizabeth Sarnoff & Jim Galasso                Sawyer   \n",
       "7              Melinda Hsu Taylor & Greggory Nations               Richard   \n",
       "8                    Paul Zbyszewski & Graham Roland             Sun & Jin   \n",
       "9                      Carlton Cuse & Damon Lindelof               Desmond   \n",
       "10                     Edward Kitsis & Adam Horowitz                Hurley   \n",
       "11                   Paul Zbyszewski & Graham Roland               Various   \n",
       "12                   Elizabeth Sarnoff & Jim Galasso          Jack & Locke   \n",
       "13                     Carlton Cuse & Damon Lindelof  Jacob & Man in Black   \n",
       "14  Edward Kitsis, Adam Horowitz & Elizabeth Sarnoff               Various   \n",
       "\n",
       "   Original air date U.S. viewers (million)  \n",
       "0     February2,2010                  12.09  \n",
       "1     February9,2010                  11.05  \n",
       "2    February16,2010                   9.82  \n",
       "3    February23,2010                   9.95  \n",
       "4        March2,2010                   9.29  \n",
       "5        March9,2010                   9.49  \n",
       "6       March16,2010                   8.87  \n",
       "7       March23,2010                   9.31  \n",
       "8       March30,2010                  10.13  \n",
       "9        April6,2010                   9.55  \n",
       "10      April13,2010                   9.48  \n",
       "11      April20,2010                   9.53  \n",
       "12         May4,2010                   9.59  \n",
       "13        May11,2010                  10.32  \n",
       "14        May18,2010                  10.47  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  에피소드에서 Jack & Locke이 나오는 에피소드 번호는 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "idx = 1039\n",
    "\n",
    "tb = [train_table[train_data[idx]['table_id']]]\n",
    "hds = [tb[0]['header']]\n",
    "nlu_t = [train_data[idx]['question_tok']]\n",
    "nlu = [train_data[idx]['question']]\n",
    "sql = [train_data[idx]['sql']]\n",
    "\n",
    "display(pd.DataFrame(tb[0]['rows'], columns=tb[0]['header']))\n",
    "\n",
    "print('Question: ',nlu[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-remove",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "racial-specialist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T07:27:00.937809Z",
     "start_time": "2021-05-07T07:27:00.029485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pick #</th>\n",
       "      <th>CFL Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Position</th>\n",
       "      <th>College</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Hamilton Tiger-Cats (via Montreal via Hamilton)</td>\n",
       "      <td>Robert Pavlovic</td>\n",
       "      <td>TE</td>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>Edmonton Eskimos</td>\n",
       "      <td>Micheal Jean-louis</td>\n",
       "      <td>DL</td>\n",
       "      <td>Laval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Edmonton Eskimos (via Winnipeg)</td>\n",
       "      <td>Calvin McCarty</td>\n",
       "      <td>RB</td>\n",
       "      <td>Western Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Saskatchewan Roughriders</td>\n",
       "      <td>Ryan Ackerman</td>\n",
       "      <td>OL</td>\n",
       "      <td>Regina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>Toronto Argonauts</td>\n",
       "      <td>Eric Maranda</td>\n",
       "      <td>LB</td>\n",
       "      <td>Laval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>Toronto Argonauts (via Calgary)</td>\n",
       "      <td>Steve Schmidt</td>\n",
       "      <td>TE</td>\n",
       "      <td>San Diego State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>Montreal Alouettes</td>\n",
       "      <td>James Judges</td>\n",
       "      <td>DE</td>\n",
       "      <td>Buffalo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pick #                                         CFL Team  \\\n",
       "0      25  Hamilton Tiger-Cats (via Montreal via Hamilton)   \n",
       "1      26                                 Edmonton Eskimos   \n",
       "2      27                  Edmonton Eskimos (via Winnipeg)   \n",
       "3      28                         Saskatchewan Roughriders   \n",
       "4      29                                Toronto Argonauts   \n",
       "5      30                  Toronto Argonauts (via Calgary)   \n",
       "6      31                               Montreal Alouettes   \n",
       "\n",
       "               Player Position             College  \n",
       "0     Robert Pavlovic       TE      South Carolina  \n",
       "1  Micheal Jean-louis       DL               Laval  \n",
       "2      Calvin McCarty       RB  Western Washington  \n",
       "3       Ryan Ackerman       OL              Regina  \n",
       "4        Eric Maranda       LB               Laval  \n",
       "5       Steve Schmidt       TE     San Diego State  \n",
       "6        James Judges       DE             Buffalo  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Calvin McCarty은 무슨 college에서 뛰었나요?\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "\n",
    "tb = [test_table[test_data[idx]['table_id']]]\n",
    "hds = [tb[0]['header']]\n",
    "nlu_t = [test_data[idx]['question_tok']]\n",
    "nlu = [test_data[idx]['question']]\n",
    "sql = [test_data[idx]['sql']]\n",
    "\n",
    "display(pd.DataFrame(tb[0]['rows'], columns=tb[0]['header']))\n",
    "\n",
    "print('Question: ',nlu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "answering-secret",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T07:27:01.720492Z",
     "start_time": "2021-05-07T07:27:00.939310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Logical Form\n",
      "==============================\n",
      "[PRED]:  SELECT (College) FROM 1-10812403-4 WHERE Player = calvin mccarty\n",
      "[TRUE]:  SELECT (College) FROM 1-10812403-4 WHERE Player = Calvin McCarty\n",
      "\n",
      "==============================\n",
      "Execution\n",
      "==============================\n",
      "[PRED]:  western washington\n",
      "[TRUE]:  western washington\n"
     ]
    }
   ],
   "source": [
    "inference(inputs=[nlu, nlu_t, hds, tb], \n",
    "          sql=sql, \n",
    "          datadir=args.datadir, \n",
    "          bert_config=bert_config, \n",
    "          model_bert=model_bert, \n",
    "          tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-spanish",
   "metadata": {},
   "source": [
    "# Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cultural-kidney",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:30.712845Z",
     "start_time": "2021-05-09T04:06:30.694423Z"
    }
   },
   "outputs": [],
   "source": [
    "args.datadir = '../data/ko_token'\n",
    "args.logdir = '../logs/ko_token'\n",
    "args.bert_name = 'bert-base-multilingual-cased'\n",
    "args.bS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scheduled-simulation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:42.054024Z",
     "start_time": "2021-05-09T04:06:30.714305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT: pretrained bert-base-multilingual-cased\n",
      "BERT: learning rate: 1e-05\n",
      "BERT: Fine-tune BERT: False\n",
      "Seq-to-SQL: the number of final BERT layers to be used: 2\n",
      "Seq-to-SQL: the size of hidden dimension = 100\n",
      "Seq-to-SQL: LSTM encoding layer size = 2\n",
      "Seq-to-SQL: dropout rate = 0.3\n",
      "Seq-to-SQL: learning rate = 0.001\n"
     ]
    }
   ],
   "source": [
    "train_data, train_table, dev_data, dev_table, test_data, test_table, _, _, test_loader = get_data(args.datadir, args)\n",
    "\n",
    "\n",
    "# To start from the pre-trained models, un-comment following lines.\n",
    "path_model_bert = os.path.join(args.logdir, 'model_bert_best.pt')\n",
    "path_model = os.path.join(args.logdir, 'model_best.pt')\n",
    "model, model_bert, tokenizer, bert_config = get_models(args, \n",
    "                                                       trained=True,\n",
    "                                                       path_model_bert=path_model_bert, \n",
    "                                                       path_model=path_model, \n",
    "                                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "central-price",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T04:06:42.075173Z",
     "start_time": "2021-05-09T04:06:42.055355Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_bert.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-proceeding",
   "metadata": {},
   "source": [
    "# Top K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "working-causing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:19.146593Z",
     "start_time": "2021-05-09T09:45:19.062722Z"
    }
   },
   "outputs": [],
   "source": [
    "def beam_search(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, engine, tb,\n",
    "                nlu_t, nlu_wp_t, wp_to_wh_index, nlu,\n",
    "                beam_size=4):\n",
    "    # sc\n",
    "    s_sc = model.scp(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, show_p_sc=False)\n",
    "    prob_sc = F.softmax(s_sc, dim=-1)\n",
    "    bS, mcL = s_sc.shape\n",
    "\n",
    "    # minimum_hs_length = min(l_hs)\n",
    "    # beam_size = minimum_hs_length if beam_size > minimum_hs_length else beam_size\n",
    "\n",
    "    # sa\n",
    "    if mcL < beam_size:\n",
    "        beam_size_mcL = mcL\n",
    "    else:\n",
    "        beam_size_mcL = beam_size\n",
    "        \n",
    "    # Construct all possible sc_sa_score\n",
    "    prob_sc_sa = torch.zeros([bS, beam_size_mcL, model.n_agg_ops]).to(device)\n",
    "    prob_sca = torch.zeros_like(prob_sc_sa).to(device)\n",
    "\n",
    "    # get the top-k indices.  pr_sc_beam = [B, beam_size]\n",
    "    \n",
    "    pr_sc_beam = pred_sc_beam(s_sc, beam_size_mcL)\n",
    "\n",
    "    # calculate and predict s_sa.\n",
    "    for i_beam in range(beam_size_mcL):\n",
    "        pr_sc = list( array(pr_sc_beam)[:,i_beam] )\n",
    "        s_sa = model.sap(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, pr_sc, show_p_sa=False)\n",
    "        prob_sa = F.softmax(s_sa, dim=-1)\n",
    "        prob_sc_sa[:, i_beam, :] = prob_sa\n",
    "\n",
    "        prob_sc_selected = prob_sc[range(bS), pr_sc] # [B]\n",
    "        prob_sca[:,i_beam,:] =  (prob_sa.t() * prob_sc_selected).t()\n",
    "        # [mcL, B] * [B] -> [mcL, B] (element-wise multiplication)\n",
    "        # [mcL, B] -> [B, mcL]\n",
    "\n",
    "    # Calculate the dimension of tensor\n",
    "    # tot_dim = len(prob_sca.shape)\n",
    "\n",
    "    # First flatten to 1-d\n",
    "    if np.prod(prob_sca.shape[1:]) < beam_size:\n",
    "        beam_size_sca = np.prod(prob_sca.shape[1:])\n",
    "    else:\n",
    "        beam_size_sca = beam_size\n",
    "    idxs_s, values_s = topk_multi_dim(torch.tensor(prob_sca), n_topk=beam_size_sca, batch_exist=True)\n",
    "    # Now as sc_idx is already sorted, re-map them properly.\n",
    "\n",
    "    idxs_s = remap_sc_idx(idxs_s, pr_sc_beam) # [sc_beam_idx, sa_idx] -> [sc_idx, sa_idx]\n",
    "    idxs_arr = array(idxs_s)\n",
    "    # [B, beam_size, remainig dim]\n",
    "    # idxs[b][0] gives first probable [sc_idx, sa_idx] pairs.\n",
    "    # idxs[b][1] gives of second.\n",
    "\n",
    "    # Calculate prob_sca, a joint probability\n",
    "    beam_idx_sca = [0] * bS\n",
    "    beam_meet_the_final = [False] * bS\n",
    "\n",
    "    while True:\n",
    "        pr_sc = idxs_arr[range(bS),beam_idx_sca,0]\n",
    "        pr_sa = idxs_arr[range(bS),beam_idx_sca,1]\n",
    "\n",
    "        # map index properly\n",
    "        check = check_sc_sa_pairs(tb, pr_sc, pr_sa)\n",
    "\n",
    "        if sum(check) == bS:\n",
    "            break\n",
    "        else:\n",
    "            for b, check1 in enumerate(check):\n",
    "                if not check1: # wrong pair\n",
    "                    beam_idx_sca[b] += 1\n",
    "                    if beam_idx_sca[b] >= beam_size_sca:\n",
    "                        beam_meet_the_final[b] = True\n",
    "                        beam_idx_sca[b] -= 1\n",
    "                else:\n",
    "                    beam_meet_the_final[b] = True\n",
    "\n",
    "        if sum(beam_meet_the_final) == bS:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Now pr_sc, pr_sa are properly predicted.\n",
    "    pr_sc_best = list(pr_sc)\n",
    "    pr_sa_best = list(pr_sa)\n",
    "\n",
    "    # Now, Where-clause beam search.\n",
    "    s_wn = model.wnp(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, show_p_wn=False)\n",
    "    prob_wn = F.softmax(s_wn, dim=-1).detach().to('cpu').numpy()\n",
    "\n",
    "    # Found \"executable\" most likely 4(=max_num_of_conditions) where-clauses.\n",
    "    # wc\n",
    "    s_wc = model.wcp(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, show_p_wc=False, penalty=True)\n",
    "    prob_wc = F.sigmoid(s_wc).detach().to('cpu').numpy()\n",
    "    # pr_wc_sorted_by_prob = pred_wc_sorted_by_prob(s_wc)\n",
    "\n",
    "    # get max_wn # of most probable columns & their prob.\n",
    "    pr_wn_max = [model.max_wn]*bS\n",
    "    pr_wc_max = pred_wc(pr_wn_max, s_wc) # if some column do not have executable where-claouse, omit that column\n",
    "    prob_wc_max = zeros([bS, model.max_wn])\n",
    "    for b, pr_wc_max1 in enumerate(pr_wc_max):\n",
    "        prob_wc_max[b,:] = prob_wc[b,pr_wc_max1]\n",
    "\n",
    "    # get most probable max_wn where-clouses\n",
    "    # wo\n",
    "    s_wo_max = model.wop(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, wn=pr_wn_max, wc=pr_wc_max, show_p_wo=False)\n",
    "    prob_wo_max = F.softmax(s_wo_max, dim=-1).detach().to('cpu').numpy()\n",
    "    # [B, max_wn, n_cond_op]\n",
    "\n",
    "    pr_wvi_beam_op_list = []\n",
    "    prob_wvi_beam_op_list = []\n",
    "    for i_op  in range(model.n_cond_ops-1):\n",
    "        pr_wo_temp = [ [i_op]*model.max_wn ]*bS\n",
    "        # wv\n",
    "        s_wv = model.wvp(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, wn=pr_wn_max, wc=pr_wc_max, wo=pr_wo_temp, show_p_wv=False)\n",
    "        prob_wv = F.softmax(s_wv, dim=-2).detach().to('cpu').numpy()\n",
    "\n",
    "        # prob_wv\n",
    "        pr_wvi_beam, prob_wvi_beam = pred_wvi_se_beam(model.max_wn, s_wv, beam_size)\n",
    "        pr_wvi_beam_op_list.append(pr_wvi_beam)\n",
    "        prob_wvi_beam_op_list.append(prob_wvi_beam)\n",
    "        # pr_wvi_beam = [B, max_wn, k_logit**2 [st, ed] paris]\n",
    "\n",
    "        # pred_wv_beam\n",
    "\n",
    "    # Calculate joint probability of where-clause\n",
    "    # prob_w = [batch, wc, wo, wv] = [B, max_wn, n_cond_op, n_pairs]\n",
    "    n_wv_beam_pairs = prob_wvi_beam.shape[2]\n",
    "    prob_w = zeros([bS, model.max_wn, model.n_cond_ops-1, n_wv_beam_pairs])\n",
    "    for b in range(bS):\n",
    "        for i_wn in range(model.max_wn):\n",
    "            for i_op in range(model.n_cond_ops-1): # do not use final one\n",
    "                for i_wv_beam in range(n_wv_beam_pairs):\n",
    "                    # i_wc = pr_wc_max[b][i_wn] # already done\n",
    "                    p_wc = prob_wc_max[b, i_wn]\n",
    "                    p_wo = prob_wo_max[b, i_wn, i_op]\n",
    "                    p_wv = prob_wvi_beam_op_list[i_op][b, i_wn, i_wv_beam]\n",
    "\n",
    "                    prob_w[b, i_wn, i_op, i_wv_beam] = p_wc * p_wo * p_wv\n",
    "\n",
    "    # Perform execution guided decoding\n",
    "    conds_max = []\n",
    "    prob_conds_max = []\n",
    "\n",
    "    if 4 < beam_size:\n",
    "        beam_size_w = 4\n",
    "    else:\n",
    "        beam_size_w = beam_size\n",
    "        \n",
    "    idxs_w, values_w = topk_multi_dim(torch.tensor(prob_w), n_topk=beam_size_w, batch_exist=True)\n",
    "    # idxs = [B, i_wc_beam, i_op, i_wv_pairs]\n",
    "\n",
    "    # Construct conds1\n",
    "    for b, idxs1 in enumerate(idxs_w):\n",
    "        conds_max1 = []\n",
    "        prob_conds_max1 = []\n",
    "        for i_wn, idxs11 in enumerate(idxs1):\n",
    "            i_wc = pr_wc_max[b][idxs11[0]]\n",
    "            i_op = idxs11[1]\n",
    "            wvi = pr_wvi_beam_op_list[i_op][b][idxs11[0]][idxs11[2]]\n",
    "\n",
    "            # get wv_str\n",
    "            temp_pr_wv_str, _ = convert_pr_wvi_to_string([[wvi]], [nlu_t[b]], [nlu_wp_t[b]], [wp_to_wh_index[b]], [nlu[b]])\n",
    "            merged_wv11 = merge_wv_t1_eng(temp_pr_wv_str[0][0], nlu[b])\n",
    "            conds11 = [i_wc, i_op, merged_wv11]\n",
    "\n",
    "            prob_conds11 = prob_w[b, idxs11[0], idxs11[1], idxs11[2] ]\n",
    "\n",
    "            # test execution\n",
    "            pr_ans = engine.execute(tb[b]['id'], pr_sc[b], pr_sa[b], [conds11])\n",
    "            if bool(pr_ans):\n",
    "                # pr_ans is not empty!\n",
    "                conds_max1.append(conds11)\n",
    "                prob_conds_max1.append(prob_conds11)\n",
    "\n",
    "        conds_max.append(conds_max1)\n",
    "        prob_conds_max.append(prob_conds_max1)\n",
    "\n",
    "        # May need to do more exhuastive search?\n",
    "        # i.e. up to.. getting all executable cases.\n",
    "\n",
    "    # Calculate total probability to decide the number of where-clauses\n",
    "    pr_sql_i = []\n",
    "    prob_wn_w = []\n",
    "    pr_wn_based_on_prob = []     \n",
    "\n",
    "    for b, prob_wn1 in enumerate(prob_wn):\n",
    "        max_executable_wn1 = len( conds_max[b] )\n",
    "\n",
    "        prob_wn_w1 = []\n",
    "        prob_wn_w1.append(prob_wn1[0])  # wn=0 case.\n",
    "        for i_wn in range(max_executable_wn1):\n",
    "            prob_wn_w11 = prob_wn1[i_wn+1] * prob_conds_max[b][i_wn]\n",
    "            prob_wn_w1.append(prob_wn_w11)\n",
    "        pr_wn_based_on_prob.append(argmax(prob_wn_w1))\n",
    "        prob_wn_w.append(prob_wn_w1)\n",
    "\n",
    "        pr_sql_i1 = {'agg': pr_sa_best[b], 'sel': pr_sc_best[b], 'conds': conds_max[b][:pr_wn_based_on_prob[b]]}\n",
    "        pr_sql_i.append(pr_sql_i1)\n",
    "\n",
    "\n",
    "    #=================\n",
    "    # top k \n",
    "    #=================\n",
    "    \n",
    "    beam_size_sca = idxs_arr.shape[1]\n",
    "    pr_sc_topk = np.zeros((bS, beam_size_sca), dtype=np.int)\n",
    "    for i in range(beam_size_sca):\n",
    "        pr_sc_i = idxs_arr[range(bS),i,0]\n",
    "        pr_sa_i = idxs_arr[range(bS),i,1]\n",
    "\n",
    "        # map index properly\n",
    "\n",
    "        check = check_sc_sa_pairs(tb, pr_sc_i, pr_sa_i)\n",
    "\n",
    "        for b, check_b in enumerate(check):\n",
    "            if check_b: # wrong pair\n",
    "                pr_sc_topk[b][i] += 1\n",
    "\n",
    "    values_s = values_s * pr_sc_topk\n",
    "\n",
    "    total_prob = np.zeros((bS, beam_size_sca, 5))\n",
    "\n",
    "    for b, prob_wn1 in enumerate(prob_wn):\n",
    "        max_executable_wn1 = len( conds_max[b] )\n",
    "        prob_wn_w1 = []\n",
    "        prob_wn_w1.append(prob_wn1[0])  # wn=0 case.\n",
    "\n",
    "        for sc_sa_idx, i_sc_sa in enumerate(values_s[b]):\n",
    "            total_prob[b][sc_sa_idx][0] = i_sc_sa * prob_wn1[0] # wn=0 case.\n",
    "\n",
    "            for w_idx, i_wn in enumerate(range(max_executable_wn1)):\n",
    "\n",
    "                prob_wn_w11 = prob_wn1[i_wn+1] * prob_conds_max[b][i_wn]\n",
    "\n",
    "                total_prob[b][sc_sa_idx][i_wn+1] = i_sc_sa * prob_wn_w11\n",
    "\n",
    "    if np.prod(total_prob.shape[1:]) < beam_size:\n",
    "        beam_size_total = np.prod(total_prob.shape[1:])\n",
    "    else:\n",
    "        beam_size_total = beam_size\n",
    "    idx_total, values_total = topk_multi_dim(torch.tensor(total_prob), n_topk=beam_size_total, batch_exist=True)\n",
    "\n",
    "    # top k sql\n",
    "    pr_sql_topk = []\n",
    "    for b, idx in enumerate(idx_total):\n",
    "        pr_sql_topk_i = []\n",
    "        for k, idx_k in enumerate(idx):\n",
    "            pr_sql_k = {'agg': idxs_arr[b][idx_k[0]][1], \n",
    "                        'sel': idxs_arr[b][idx_k[0]][0], \n",
    "                        'conds': conds_max[b][:idx_k[1]]}\n",
    "\n",
    "            pr_sql_topk_i.append(pr_sql_k)\n",
    "\n",
    "        pr_sql_topk.append(pr_sql_topk_i)\n",
    "        \n",
    "    return pr_sql_topk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eastern-graph",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:19.761499Z",
     "start_time": "2021-05-09T09:45:19.737485Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def topk_acc(bS, tb, topk_x_acc, topk_lx_acc, \n",
    "             g_sc, g_sa, g_wn, g_wc, g_wo, g_wv, sql_i, pr_sql_topk_i):\n",
    "    \n",
    "    cnt_x = np.zeros(bS, dtype=np.int)\n",
    "    cnt_lx = np.zeros(bS, dtype=np.int)\n",
    "\n",
    "    for i in range(beam_size):\n",
    "        pr_sql_b = np.array(pr_sql_topk_i)[:,i]\n",
    "\n",
    "        pr_wc, pr_wo, pr_wv, pr_sql_i = sort_and_generate_pr_w(pr_sql_b)\n",
    "        pr_sc = [pr_sql['sel'] for pr_sql in pr_sql_b]\n",
    "        pr_sa = [pr_sql['agg'] for pr_sql in pr_sql_b]\n",
    "        pr_wn = [len(pr_sql['conds']) for pr_sql in pr_sql_b]\n",
    "\n",
    "        # where value index is None\n",
    "        g_wvi = None\n",
    "        pr_wvi = None\n",
    "\n",
    "        cnt_sc1_list, cnt_sa1_list, cnt_wn1_list, \\\n",
    "        cnt_wc1_list, cnt_wo1_list, \\\n",
    "        cnt_wvi1_list, cnt_wv1_list = get_cnt_sw_list(g_sc, g_sa, g_wn, g_wc, g_wo, g_wvi,\n",
    "                                                      pr_sc, pr_sa, pr_wn, pr_wc, pr_wo, pr_wvi,\n",
    "                                                      sql_i, pr_sql_b,\n",
    "                                                      mode='test')\n",
    "\n",
    "        # Logical Form\n",
    "        cnt_lx1_list = get_cnt_lx_list(cnt_sc1_list, cnt_sa1_list, cnt_wn1_list, cnt_wc1_list,\n",
    "                                       cnt_wo1_list, cnt_wv1_list)\n",
    "        cnt_lx += cnt_lx1_list\n",
    "\n",
    "        cnt_lx_k = sum(cnt_lx > 0)\n",
    "\n",
    "        if f'Top-{i+1} lx' in topk_lx_acc.keys():\n",
    "            topk_lx_acc[f'Top-{i+1} lx'] += cnt_lx_k\n",
    "\n",
    "        # Execution \n",
    "        cnt_x1_list, _, _ = get_cnt_x_list(engine, tb, sql_i, pr_sql_b)\n",
    "        cnt_x += cnt_x1_list\n",
    "\n",
    "        cnt_x_k = sum(cnt_x > 0)\n",
    "\n",
    "        if f'Top-{i+1} x' in topk_x_acc.keys():\n",
    "            topk_x_acc[f'Top-{i+1} x'] += cnt_x_k\n",
    "            \n",
    "    return topk_lx_acc, topk_x_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "anticipated-glasgow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:20.193776Z",
     "start_time": "2021-05-09T09:45:20.172170Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_topk(engine, t, data_table, beam_size, k_lst, topk_lx_acc, topk_x_acc):\n",
    "\n",
    "    # get fields\n",
    "    nlu, nlu_t, sql_i, sql_q, sql_t, tb, hs_t, hds = get_fields(t, data_table, no_hs_t=True, no_sql_t=True)\n",
    "\n",
    "\n",
    "    # prediction\n",
    "    wemb_n, wemb_hpu, l_n, l_hpu, l_hs, \\\n",
    "    nlu_wp_t, t_to_tt_idx, wp_to_wh_index = get_wemb_bert(bert_config, \n",
    "                                                         model_bert, \n",
    "                                                         tokenizer, \n",
    "                                                         nlu_t, \n",
    "                                                         hds, \n",
    "                                                         args.max_seq_length,\n",
    "                                                         num_out_layers_n=args.num_target_layers, \n",
    "                                                         num_out_layers_h=args.num_target_layers,\n",
    "                                                         device=device)\n",
    "\n",
    "    # beam search\n",
    "    pr_sql_topk_i = beam_search(wemb_n, l_n, wemb_hpu, l_hpu, l_hs, engine, tb,\n",
    "                                nlu_t, nlu_wp_t, wp_to_wh_index, nlu,\n",
    "                                beam_size=beam_size)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    g_sc, g_sa, g_wn, g_wc, g_wo, g_wv = get_g(sql_i)\n",
    "    \n",
    "    topk_lx_acc, topk_x_acc = topk_acc(len(t), tb, topk_x_acc, topk_lx_acc, \n",
    "                                       g_sc, g_sa, g_wn, g_wc, g_wo, g_wv, sql_i, pr_sql_topk_i)\n",
    "\n",
    "    \n",
    "    return topk_lx_acc, topk_x_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "revolutionary-graph",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:20.856099Z",
     "start_time": "2021-05-09T09:45:20.834537Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = DBEngine(os.path.join(args.datadir, 'test.db'))\n",
    "data_table = test_table\n",
    "\n",
    "beam_size = 64\n",
    "k_lst = [1,2,3,4,5,10]\n",
    "\n",
    "# top k\n",
    "topk_x_acc = dict([(f'Top-{k} x',0) for k in k_lst])\n",
    "topk_lx_acc = dict([(f'Top-{k} lx',0) for k in k_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "beneficial-playlist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:23.740154Z",
     "start_time": "2021-05-09T09:45:21.560839Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    t = test_loader.dataset[i:i+4]\n",
    "    \n",
    "    topk_lx_acc, topk_x_acc = inference_topk(engine, t, data_table, beam_size, k_lst, \n",
    "                                             topk_lx_acc, topk_x_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "devoted-philip",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:24.314058Z",
     "start_time": "2021-05-09T09:45:24.294496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top-1 lx': 7,\n",
       " 'Top-2 lx': 7,\n",
       " 'Top-3 lx': 7,\n",
       " 'Top-4 lx': 7,\n",
       " 'Top-5 lx': 7,\n",
       " 'Top-10 lx': 8}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_lx_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ambient-bulgaria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T09:45:24.978896Z",
     "start_time": "2021-05-09T09:45:24.958028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Top-1 x': 7,\n",
       " 'Top-2 x': 7,\n",
       " 'Top-3 x': 7,\n",
       " 'Top-4 x': 7,\n",
       " 'Top-5 x': 7,\n",
       " 'Top-10 x': 8}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_x_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-uganda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
